Chapter 7<br/>
< L2 - Regularization / Ridge >
===============================


### L2 Regularization
- 기존 Cost function L2(norm) 패널티 term을 추가<br/>
<img src="https://github.com/alstn2468/Python_For_Machine_Learning/blob/master/Chapter.7/img/30.png" width="300" height="auto">
- norm : 벡터의 길이 혹은 크기를 측정하는 방법<br/>
- L2 : Euclidean distance, 원점에서 벡터 좌표까지의 거리<img src="https://github.com/alstn2468/Python_For_Machine_Learning/blob/master/Chapter.7/img/31.png" width="100" height="auto">
- m : 데이터의 개수<br/>
- λ : 지정한 폭<br/>
- α : Learning rate<br/>
- (1 - (α * λ / m)) 항상 1보다 작다.<br/>

<img src="https://github.com/alstn2468/Python_For_Machine_Learning/blob/master/Chapter.7/img/32.png" width="300" height="auto"><br/>
<img src="https://github.com/alstn2468/Python_For_Machine_Learning/blob/master/Chapter.7/img/33.png" width="300" height="auto">

<br/>

### Normal equation approach
<img src="https://github.com/alstn2468/Python_For_Machine_Learning/blob/master/Chapter.7/img/34.png" width="300" height="auto"><br/>
<img src="https://github.com/alstn2468/Python_For_Machine_Learning/blob/master/Chapter.7/img/35.png" width="300" height="auto">

<br/>

### L1 Regularization
- 기존 Cost function L1(norm) 패널티 term을 추가
- L2 보다 패널티가 적다(절댓값).
<img src="https://github.com/alstn2468/Python_For_Machine_Learning/blob/master/Chapter.7/img/36.png" width="300" height="auto">
- L1 : manhattan distance<br/>
<img src="https://github.com/alstn2468/Python_For_Machine_Learning/blob/master/Chapter.7/img/37.png" width="200" height="auto">

<br/>

### L1 vs L2
- 둘 다 w의 값을 제한
- L1 : 절댓값
- L2 : 제곱, s가 커질수록 원이 커진다.
- L1과 L2의 차이점<br/>
-> L2는 하나의 점에서만 만날 수 있지만, L1은 여러 점에서 만날 수 있다.<br/>
<img src="https://github.com/alstn2468/Python_For_Machine_Learning/blob/master/Chapter.7/img/38.png" width="300" height="auto">

- L1<br/>
> Unstable solution<br/>
> Always on solution<br/>
> Sparse solution<br/>
> Feature selection

- L2<br/>
> Stable solution<br/>
> Only one solution<br/>
> Non-sparse solution
