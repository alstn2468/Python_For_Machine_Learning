
Chapter 7<br/>
< Performance measure >
===============================

[[실행 코드]](https://github.com/alstn2468/Python_For_Machine_Learning/blob/master/Chapter.8/8.ipynb)


## Regression Metrixs


### Mean Absolute Error(MAE)
- 잔차의 절대값의 Sum

<img src="https://github.com/alstn2468/Python_For_Machine_Learning/blob/master/Chapter.7/img/20.png" width="400" height="auto">

```python
from sklearn.metrics import median_absolute_error

y_true = [3, -0.5, 2, 7]
y_pred = [2.5, 0.0, 2, 8]

median_absolute_error(y_true, y_pred)
```




    0.5



### Root Mean Squared Error(RMSE)
- 잔차 제곱의 sum의 루트

<img src="https://github.com/alstn2468/Python_For_Machine_Learning/blob/master/Chapter.7/img/21.png" width="400" height="auto">

```python
from sklearn.metrics import mean_squared_error

y_true = [3, -0.5, 2, 7]
y_pred = [2.5, 0.0, 2, 8]

mean_squared_error(y_true, y_pred)
```




    0.375



### R squared
- 0과 1사이 숫자로 크면 클 수록 높은 적합도를 지닌다.

<img src="https://github.com/alstn2468/Python_For_Machine_Learning/blob/master/Chapter.7/img/22.png" width="400" height="auto">


```python
from sklearn.metrics import r2_score

y_true = [3, -0.5, 2, 7]
y_pred = [2.5, 0.0, 2, 8]

r2_score(y_true, y_pred)
```




    0.94860813704496794



### Training & Test data set
- Training한 데이터로 다시 Test를 할 경우<br/>
Training 데이터에 과도하게 fitting된 모델이 사용될 수 있다.
- 새로운 데이터가 출현했을 때, 기존 모델과의 차이 존재
- 모델은 새로운 데이터가 처리가능하도록 generalize되어야한다.
- 이를 위해 Training Set과 Test Set을 분리


### Holdout Method(Sampling)
- 데이터를 Training과 Test로 나눠서 모델을 생성하고 테스트하는 기법
- 가장 일반적인 모델 생성을 위한 데이터 랜덤 샘플링 기법
- Training과 Test를 나누는 비율은 데이터의 크기에 따라 다르다.
- 일반적으로 Training Data : Test Data =  2 : 1 활용


```python
import numpy as np
from sklearn.model_selection import train_test_split

X, y = np.arange(10).reshape((5, 2)), range(5)

X_train, X_test, y_train, y_test = train_test_split(
                                X, y, test_size = 0.33, random_state = 42)
```
