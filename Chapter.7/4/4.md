
Chapter 7<br/>
< Assignment - Normal equation >
===============================

[[실행 코드]](https://github.com/alstn2468/Python_For_Machine_Learning/blob/master/Chapter.7/4/4.ipynb)

### 1. Import Modules


```python
import pandas as pd
import numpy as np
```

### 2. Load Dataset - Simple Variable


```python
df = pd.read_csv('./data/test.csv')
df.head()
```




<div>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>x</th>
      <th>y</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>77</td>
      <td>79.775152</td>
    </tr>
    <tr>
      <th>1</th>
      <td>21</td>
      <td>23.177279</td>
    </tr>
    <tr>
      <th>2</th>
      <td>22</td>
      <td>25.609262</td>
    </tr>
    <tr>
      <th>3</th>
      <td>20</td>
      <td>17.857388</td>
    </tr>
    <tr>
      <th>4</th>
      <td>36</td>
      <td>41.849864</td>
    </tr>
  </tbody>
</table>
</div>




```python
X = df['x'].values.reshape(-1, 1)
y = df['y'].values
```

### 3. Build Model


```python
import normal_equation_lr
import imp
imp.reload(normal_equation_lr)
```




    <module 'normal_equation_lr' from '/Users/blueprint/Documents/Python/Python_For_Machine_Learning/Chapter.7/normal_equation_lr.py'>




```python
lr = normal_equation_lr.LinearRegression(fit_intercept = True)
```


```python
lr.fit(X, y)
```


```python
lr.intercept
```




    -0.46181077366097156




```python
lr.coef
```




    array([ 1.01433536])




```python
lr.predict(X)[:10]
```




    array([ 77.64201157,  20.83923168,  21.85356704,  19.82489633,
            36.05426201,  14.75321955,  62.42698124,  95.90004796,
            19.82489633,   4.609866  ])



### 4. Validation


```python
from sklearn import linear_model
sk_lr = linear_model.LinearRegression(normalize = True)
sk_lr.fit(X, y)
```

    /anaconda3/lib/python3.6/site-packages/scipy/linalg/basic.py:1018: RuntimeWarning: internal gelsd driver lwork query error, required iwork dimension not returned. This is likely the result of LAPACK bug 0038, fixed in LAPACK 3.2.2 (released July 21, 2010). Falling back to 'gelss' driver.
      warnings.warn(mesg, RuntimeWarning)





    LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=True)




```python
sk_lr.intercept_
```




    -0.46181077366117762




```python
import numpy.testing as npt
npt.assert_almost_equal(sk_lr.intercept_, lr.intercept)
```


```python
sk_lr.coef_
```




    array([ 1.01433536])




```python
lr.coef
```




    array([ 1.01433536])




```python
np.isclose(lr.coef, sk_lr.coef_)
```




    array([ True], dtype=bool)




```python
df_test = pd.read_csv('./data/train.csv')
df_test.head()
```




<div>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>x</th>
      <th>y</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>24</td>
      <td>21.549452</td>
    </tr>
    <tr>
      <th>1</th>
      <td>50</td>
      <td>47.464463</td>
    </tr>
    <tr>
      <th>2</th>
      <td>15</td>
      <td>17.218656</td>
    </tr>
    <tr>
      <th>3</th>
      <td>38</td>
      <td>36.586398</td>
    </tr>
    <tr>
      <th>4</th>
      <td>87</td>
      <td>87.288984</td>
    </tr>
  </tbody>
</table>
</div>




```python
X_test = df['x'].values.reshape(-1, 1)
```


```python
lr.predict(X_test)[:5]
```




    array([ 77.64201157,  20.83923168,  21.85356704,  19.82489633,  36.05426201])




```python
sk_lr.predict(X_test)[:5]
```




    array([ 77.64201157,  20.83923168,  21.85356704,  19.82489633,  36.05426201])



### 5. Load Dataset - Multiple Variables


```python
df = pd.read_csv('./data/mlr09.csv')
df.head()
```




<div>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>height_in_feet</th>
      <th>weight_in_pounds</th>
      <th>successful_field_goals</th>
      <th>percent_of_successful_free_throws</th>
      <th>average_points_scored</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>6.8</td>
      <td>225</td>
      <td>0.442</td>
      <td>0.672</td>
      <td>9.2</td>
    </tr>
    <tr>
      <th>1</th>
      <td>6.3</td>
      <td>180</td>
      <td>0.435</td>
      <td>0.797</td>
      <td>11.7</td>
    </tr>
    <tr>
      <th>2</th>
      <td>6.4</td>
      <td>190</td>
      <td>0.456</td>
      <td>0.761</td>
      <td>15.8</td>
    </tr>
    <tr>
      <th>3</th>
      <td>6.2</td>
      <td>180</td>
      <td>0.416</td>
      <td>0.651</td>
      <td>8.6</td>
    </tr>
    <tr>
      <th>4</th>
      <td>6.9</td>
      <td>205</td>
      <td>0.449</td>
      <td>0.900</td>
      <td>23.2</td>
    </tr>
  </tbody>
</table>
</div>




```python
y = df['average_points_scored'].values
```


```python
df.iloc[:, :-1].head()
```




<div>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>height_in_feet</th>
      <th>weight_in_pounds</th>
      <th>successful_field_goals</th>
      <th>percent_of_successful_free_throws</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>6.8</td>
      <td>225</td>
      <td>0.442</td>
      <td>0.672</td>
    </tr>
    <tr>
      <th>1</th>
      <td>6.3</td>
      <td>180</td>
      <td>0.435</td>
      <td>0.797</td>
    </tr>
    <tr>
      <th>2</th>
      <td>6.4</td>
      <td>190</td>
      <td>0.456</td>
      <td>0.761</td>
    </tr>
    <tr>
      <th>3</th>
      <td>6.2</td>
      <td>180</td>
      <td>0.416</td>
      <td>0.651</td>
    </tr>
    <tr>
      <th>4</th>
      <td>6.9</td>
      <td>205</td>
      <td>0.449</td>
      <td>0.900</td>
    </tr>
  </tbody>
</table>
</div>




```python
X = df.iloc[:,:-1].values
```


```python
X[:5]
```




    array([[   6.8  ,  225.   ,    0.442,    0.672],
           [   6.3  ,  180.   ,    0.435,    0.797],
           [   6.4  ,  190.   ,    0.456,    0.761],
           [   6.2  ,  180.   ,    0.416,    0.651],
           [   6.9  ,  205.   ,    0.449,    0.9  ]])



### 6. Rescaled


```python
mu_X = np.mean(X, axis = 0)
std_X = np.std(X, axis = 0)

rescaled_X = (X - mu_X) / std_X
```


```python
rescaled_X[:5]
```




    array([[ 0.46843663,  0.50336336, -0.12692668, -0.70404955],
           [-0.63137111, -0.99746237, -0.25187012,  0.55584824],
           [-0.41140956, -0.66394554,  0.12296022,  0.19299768],
           [-0.85133266, -0.99746237, -0.59100234, -0.91571238],
           [ 0.68839818, -0.1636703 , -0.00198323,  1.59400403]])



### 7. Validation


```python
lr.fit(rescaled_X, y)
```


```python
lr.coef
```




    array([-1.67779283,  0.28359762,  2.68586629,  1.12816882])




```python
lr.intercept
```




    11.790740740740739




```python
sk_lr.fit(rescaled_X, y)
```




    LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=True)




```python
sk_lr.coef_
```




    array([-1.67779283,  0.28359762,  2.68586629,  1.12816882])




```python
sk_lr.intercept_
```




    11.790740740740736
